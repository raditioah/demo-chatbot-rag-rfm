# RAG-based LLM Chatbot for Natural Language Querying over BigQuery

This project is a Retrieval-Augmented Generation (RAG) chatbot designed to help marketing teams query customer segmentation data (RFM) stored in Google BigQuery using natural language, without needing SQL knowledge.
By combining Large Language Models (LLM) with semantic retrieval over tabular data, this chatbot improves operational efficiency and makes data querying more intuitive and accessible.

## Overview

This project is a Retrieval-Augmented Generation (RAG) chatbot designed to help marketing teams query customer segmentation data (RFM) stored in Google BigQuery using natural language, without needing SQL knowledge.
By combining Large Language Models (LLM) with semantic retrieval over tabular data, this chatbot improves operational efficiency and makes data querying more intuitive and accessible.

## Key Features

ðŸ”¹ Natural Language Querying â€“ Ask questions in plain English without writing SQL.

ðŸ”¹ BigQuery Integration â€“ Data is fetched directly from Google BigQuery.

ðŸ”¹ RFM Segmentation Support â€“ Built specifically for customer segmentation analysis.

ðŸ”¹ RAG Pipeline â€“ Embeds structured tabular data with SentenceTransformer and retrieves via FAISS.

ðŸ”¹ Streamlit UI â€“ Simple web-based interface for real-time interaction.

ðŸ”¹ LLaMA via GroqCloud API â€“ Fast, scalable inference with LLaMA-3 70B model.

## Tech Stack
ðŸ”¹ Language Model API: GroqCloud (LLaMA-3-70B-8192)

ðŸ”¹ Vector Database: FAISS
ðŸ”¹ Embedding Model: SentenceTransformers (HuggingFace)

ðŸ”¹ Data Warehouse: Google BigQuery

ðŸ”¹ Frameworks & Tools: LangChain, Streamlit, Python

## Architecture
1. Data Loading â†’ Load RFM segmentation data from BigQuery with google.cloud.bigquery.
2. Embedding & Indexing â†’ Convert structured data into embeddings using SentenceTransformer, indexed with FAISS.
3. Retrieval & Augmentation â†’ Retrieve relevant chunks for context-aware answering.
4. LLM Inference â†’ Query handled by GroqCloud LLaMA for natural language response.
5. User Interface â†’ Streamlit app for real-time chatbot interaction.

## Instalation

1. After cloning this repository, please create a folder named "ytta" or any name you like in order to store secret.toml file (this is where API KEY located)
2. Create credentials.json in order to get access to database and table from BigQuery. link: https://docs.google.com/document/d/10Q3JamUmVbxALnET7m_f_VZp0J1BukoHVmLIk0AWWuo/edit?usp=sharing
3. Create virtual environment
4. Install all requirements with pip install -r requirements.txt
5. Run the streamlit application


